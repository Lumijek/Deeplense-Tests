{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# Common Test I. Multi-Class Classification\n",
    "\n",
    "Task: Build a model for classifying the images into lenses using PyTorch or Keras. Pick the most appropriate approach and discuss your strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Imports\n",
    "We start by importing everything we will need to work with and visualize the data. I am using PyTorch to create my final solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T15:40:59.606958Z",
     "iopub.status.busy": "2024-03-11T15:40:59.606686Z",
     "iopub.status.idle": "2024-03-11T15:41:08.929654Z",
     "shell.execute_reply": "2024-03-11T15:41:08.928780Z",
     "shell.execute_reply.started": "2024-03-11T15:40:59.606933Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import v2\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T15:41:08.931218Z",
     "iopub.status.busy": "2024-03-11T15:41:08.930815Z",
     "iopub.status.idle": "2024-03-11T15:41:08.939608Z",
     "shell.execute_reply": "2024-03-11T15:41:08.938504Z",
     "shell.execute_reply.started": "2024-03-11T15:41:08.931190Z"
    }
   },
   "outputs": [],
   "source": [
    "# Seed everything for reproducibility\n",
    "SEED = 1\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the dataset\n",
    "\n",
    "The dataset contains 2 folders, train and val. Train contains 3 folders(no, sphere, and vort) with 10,000 images each and val contains the same 3 folders with 2,500 images each.\n",
    "\n",
    "I will start by creating a PyTorch Dataset to store all these images. As they are stored with the same name across different folders, I have manual checks in \\__getitem__ to determine the exact folder and index to load the image from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T15:41:44.457281Z",
     "iopub.status.busy": "2024-03-11T15:41:44.456610Z",
     "iopub.status.idle": "2024-03-11T15:41:44.468791Z",
     "shell.execute_reply": "2024-03-11T15:41:44.467821Z",
     "shell.execute_reply.started": "2024-03-11T15:41:44.457245Z"
    }
   },
   "outputs": [],
   "source": [
    "class StrongLensingDataset(Dataset):\n",
    "    def __init__(self, imgs, train=True, transform=None):\n",
    "        if(train == True):\n",
    "            folder = \"train\"\n",
    "        else:\n",
    "            folder = \"val\"\n",
    "        self.imgs = os.path.join(imgs, folder)\n",
    "        print(sum(1 for _, _, files in os.walk(self.imgs) for f in files))\n",
    "        self.len = sum(1 for _, _, files in os.walk(self.imgs) for f in files)\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.train:\n",
    "            if(idx <= 10000):\n",
    "                clss = \"no\"\n",
    "                label = 0\n",
    "            elif(idx <= 20000):\n",
    "                clss = \"sphere\"\n",
    "                label  = 1\n",
    "            elif(idx <= 30000):\n",
    "                clss = \"vort\"\n",
    "                label = 2\n",
    "            idx = idx % 10000 + 1\n",
    "        else:\n",
    "            if(idx <= 2500):\n",
    "                clss = \"no\"\n",
    "                label = 0\n",
    "            elif(idx <= 5000):\n",
    "                clss = \"sphere\"\n",
    "                label  = 1\n",
    "            elif(idx <= 7500):\n",
    "                clss = \"vort\"\n",
    "                label = 2\n",
    "            idx = idx % 2500 + 1       \n",
    "        path = os.path.join(self.imgs, clss, f\"{idx}.npy\")\n",
    "        img = torch.from_numpy(np.load(path))\n",
    "        img = img.to(torch.float32)\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a seperate function the create the DataLoader, I have decided on 3 transformations - Random rotations up to 90 degrees, random horizontal flips, and random vertical flips. This will help prevent overfitting as a good regularization technique.\n",
    "\n",
    "The images are also normalized along the datasets mean and variance to ensure a mean 0, variance 1 distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T15:41:45.126815Z",
     "iopub.status.busy": "2024-03-11T15:41:45.126413Z",
     "iopub.status.idle": "2024-03-11T15:41:45.133641Z",
     "shell.execute_reply": "2024-03-11T15:41:45.132625Z",
     "shell.execute_reply.started": "2024-03-11T15:41:45.126788Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_dataloader(file_path, train=True, batch_size=16, num_workers=1):\n",
    "    transform = v2.Compose([\n",
    "        v2.RandomRotation(90),\n",
    "        v2.RandomHorizontalFlip(p=0.5),\n",
    "        v2.RandomVerticalFlip(p=0.5),\n",
    "        v2.Normalize(mean=[0.0617], std=[0.1135]), # Values chosen to ensure mean 0 var 1\n",
    "    ])\n",
    "    if train:\n",
    "        train_dataset = StrongLensingDataset(file_path, train=train, transform=transform)\n",
    "    else:\n",
    "        train_dataset = StrongLensingDataset(file_path, train=train, transform=None)\n",
    "    train_loader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=num_workers, pin_memory=True, persistent_workers=True)\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "For the model, I settled on a ResNet18 architecture with slight modifications. I replace Relu activations with Silu alongside replacing the initial 7x7 stride 2 convolution with a 3x3 stride 1. This gave slightly more accurate results for the most part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T15:41:45.825910Z",
     "iopub.status.busy": "2024-03-11T15:41:45.825571Z",
     "iopub.status.idle": "2024-03-11T15:41:45.843818Z",
     "shell.execute_reply": "2024-03-11T15:41:45.842759Z",
     "shell.execute_reply.started": "2024-03-11T15:41:45.825883Z"
    }
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "\texpansion = 1\n",
    "\tdef __init__(self, in_planes, planes, stride=1):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.conv1 = nn.Sequential(\n",
    "\t\t\tnn.Conv2d(in_planes, planes, kernel_size=3, padding=1, bias=False),\n",
    "\t\t\tnn.BatchNorm2d(planes),\n",
    "\t\t\tnn.SiLU()\n",
    "\t\t)\n",
    "\t\tself.conv2 = nn.Sequential(\n",
    "\t\t\tnn.Conv2d(planes, planes, kernel_size=3, padding=1, stride=stride, bias=False),\n",
    "\t\t\tnn.BatchNorm2d(planes),\n",
    "\t\t\tnn.SiLU()\n",
    "\t\t)\n",
    "\t\tself.shortcut = nn.Identity()\n",
    "\t\tif stride != 1 or in_planes != self.expansion * planes:\n",
    "\t\t\tself.shortcut = nn.Sequential(\n",
    "\t\t\t\tnn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "\t\t\t\tnn.BatchNorm2d(self.expansion * planes)\n",
    "\t\t\t)\n",
    "\tdef forward(self, x):\n",
    "\t\tout = self.conv1(x)\n",
    "\t\tout = self.conv2(out)\n",
    "\n",
    "\t\tout += self.shortcut(x)\n",
    "\n",
    "\t\treturn F.silu(out)\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\tdef __init__(self, block, layers, planes=[64, 128, 256, 512], classes=3):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.in_planes = 64\n",
    "\t\tself.block = block\n",
    "\t\tself.layers = layers\n",
    "\t\tself.planes = planes\n",
    "\t\tself.classes = classes\n",
    "\n",
    "\t\tself.initial_conv = nn.Conv2d(1, 64, kernel_size=3, padding=1, bias=False)\n",
    "\t\tself.initial_bn = nn.BatchNorm2d(64)\n",
    "\n",
    "\t\tself.layer1 = self._make_layer(block, layers[0], planes[0], stride=1)\n",
    "\t\tself.layer2 = self._make_layer(block, layers[1], planes[1], stride=2)\n",
    "\t\tself.layer3 = self._make_layer(block, layers[2], planes[2], stride=2)\n",
    "\t\tself.layer4 = self._make_layer(block, layers[3], planes[3], stride=2)\n",
    "\n",
    "\t\tself.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\t\tself.fc = nn.Linear(planes[3] * block.expansion, classes)\n",
    "\n",
    "\tdef _make_layer(self, block, layer, plane, stride=1):\n",
    "\t\tstrides = [stride] + (layer - 1) * [1]\n",
    "\n",
    "\t\tconvs = []\n",
    "\t\tfor stride in strides:\n",
    "\t\t\tconvs.append(block(self.in_planes, plane, stride))\n",
    "\t\t\tself.in_planes = plane * block.expansion\n",
    "\t\treturn nn.Sequential(*convs)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tout = self.initial_conv(x)\n",
    "\t\tout = self.initial_bn(out)\n",
    "\n",
    "\t\tout = self.layer1(out)\n",
    "\t\tout = self.layer2(out)\n",
    "\t\tout = self.layer3(out)\n",
    "\t\tout = self.layer4(out)\n",
    "\t\tout = self.avgpool(out)\n",
    "\t\tout = out.view(out.size(0), -1)\n",
    "\t\tout = self.fc(out)\n",
    "\t\treturn out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Start creating all training parameters and load everything up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T15:41:47.065190Z",
     "iopub.status.busy": "2024-03-11T15:41:47.064433Z",
     "iopub.status.idle": "2024-03-11T15:43:01.087012Z",
     "shell.execute_reply": "2024-03-11T15:43:01.086188Z",
     "shell.execute_reply.started": "2024-03-11T15:41:47.065156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n",
      "7500\n"
     ]
    }
   ],
   "source": [
    "# Create dataloaders\n",
    "train_loader = get_dataloader(\"dataset\", train=True, batch_size=128)\n",
    "test_loader = get_dataloader(\"dataset\", train=False, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T15:44:56.174197Z",
     "iopub.status.busy": "2024-03-11T15:44:56.173841Z",
     "iopub.status.idle": "2024-03-11T15:44:56.298511Z",
     "shell.execute_reply": "2024-03-11T15:44:56.297364Z",
     "shell.execute_reply.started": "2024-03-11T15:44:56.174168Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 11169219\n"
     ]
    }
   ],
   "source": [
    "# Create model, loss, optimizer, and scheduler\n",
    "model = ResNet(BasicBlock, [2, 2, 2, 2], [64, 128, 256, 512], 3) # Resnet 18\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.5, patience = 5)\n",
    "epochs = 120\n",
    "\n",
    "print(\"Model size:\", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T15:44:56.793869Z",
     "iopub.status.busy": "2024-03-11T15:44:56.793530Z",
     "iopub.status.idle": "2024-03-11T15:44:56.798169Z",
     "shell.execute_reply": "2024-03-11T15:44:56.797289Z",
     "shell.execute_reply.started": "2024-03-11T15:44:56.793841Z"
    }
   },
   "outputs": [],
   "source": [
    "# Some lists for visualization after\n",
    "t_epochs = []\n",
    "t_loss = []\n",
    "t_auc = []\n",
    "t_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T15:45:57.369690Z",
     "iopub.status.busy": "2024-03-11T15:45:57.368817Z",
     "iopub.status.idle": "2024-03-11T15:45:57.389368Z",
     "shell.execute_reply": "2024-03-11T15:45:57.388269Z",
     "shell.execute_reply.started": "2024-03-11T15:45:57.369654Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, scheduler, loss_fn, train_loader, test_loader, epochs=100, device=torch.device(\"cuda\")):\n",
    "    outputfile = open(\"output.txt\", \"w\")\n",
    "    model.train()\n",
    "    model = nn.DataParallel(model)\n",
    "    model = model.to(device)\n",
    "    auroc = torchmetrics.AUROC(task=\"multiclass\", num_classes=3)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        print(\"Learning Rate:\", [group['lr'] for group in optimizer.param_groups])\n",
    "        running_loss = 0.0\n",
    "        running_accuracy = 0.0\n",
    "        running_auroc = 0.0\n",
    "        batches = 0\n",
    "        for image, label in tqdm(train_loader, desc=\"Train\"):\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "                output = model(image)\n",
    "                loss = loss_fn(output, label)\n",
    "\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            total_correct = (predicted == label).sum().item()\n",
    "            total_samples = label.size(0)\n",
    "            scores = auroc(F.softmax(output, dim=1), label)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            running_accuracy += 100 * (total_correct / total_samples)\n",
    "            running_auroc += scores.item()\n",
    "            batches += 1\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        epoch_loss_train = running_loss / batches\n",
    "        epoch_accuracy_train = running_accuracy / batches\n",
    "        epoch_auroc_train = running_auroc / batches\n",
    "        scheduler.step(epoch_loss_train)\n",
    "        \n",
    "        t_epochs.append(epoch)\n",
    "        t_loss.append(epoch_loss_train)\n",
    "        t_accuracy.append(epoch_accuracy_train)\n",
    "        t_auc.append(epoch_auroc_train)\n",
    "        with torch.no_grad():\n",
    "            running_loss = 0.0\n",
    "            running_accuracy = 0.0\n",
    "            running_auroc = 0.0\n",
    "            batches = 0\n",
    "            for image, label in tqdm(test_loader, desc=\"Test\"):\n",
    "                auroc = torchmetrics.AUROC(task=\"multiclass\", num_classes=3)\n",
    "                image = image.to(device)\n",
    "                label = label.to(device)\n",
    "\n",
    "                output = model(image)\n",
    "                loss = loss_fn(output, label)\n",
    "                \n",
    "                _, predicted = torch.max(output, 1)\n",
    "                total_correct = (predicted == label).sum().item()\n",
    "                total_samples = label.size(0)\n",
    "                scores = auroc(F.softmax(output, dim=1), label)\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                running_accuracy += 100 * (total_correct / total_samples)\n",
    "                running_auroc += scores.item()\n",
    "                batches += 1\n",
    "            epoch_loss_val = running_loss / batches\n",
    "            epoch_accuracy_val = running_accuracy / batches\n",
    "            epoch_auroc_val = running_auroc / batches\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "        print(\"Train:\")\n",
    "        print(f\"\\tLoss: {epoch_loss_train}, Accuracy: {epoch_accuracy_train}, AUROC: {epoch_auroc_train}\")\n",
    "        print(\"Validation:\")\n",
    "        print(f\"\\tLoss: {epoch_loss_val}, Accuracy: {epoch_accuracy_val}, AUROC: {epoch_auroc_val}\")\n",
    "        outputfile.write(f\"Epoch: {epoch}\\n\")\n",
    "        outputfile.write(\"Train:\\n\")\n",
    "        outputfile.write(f\"\\tLoss: {epoch_loss_train}, Accuracy: {epoch_accuracy_train}, AUROC: {epoch_auroc_train}\\n\")\n",
    "        outputfile.write(\"Validation:\\n\")\n",
    "        outputfile.write(f\"\\tLoss: {epoch_loss_val}, Accuracy: {epoch_accuracy_val}, AUROC: {epoch_auroc_val}\\n\")\n",
    "    outputfile.close()\n",
    "    torch.save(model.module.state_dict(), \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T15:45:57.919102Z",
     "iopub.status.busy": "2024-03-11T15:45:57.918365Z",
     "iopub.status.idle": "2024-03-11T15:45:58.031358Z",
     "shell.execute_reply": "2024-03-11T15:45:58.030314Z",
     "shell.execute_reply.started": "2024-03-11T15:45:57.919066Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eacb7fa853ca4c20860a4386363e510a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(model, optimizer, scheduler, loss_fn, train_loader, test_loader, epochs, device=torch.device(\"cuda\"))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4517485,
     "sourceId": 7730922,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
